{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "65ff8d7d",
   "metadata": {
    "papermill": {
     "duration": 0.004166,
     "end_time": "2022-11-17T17:37:30.126413",
     "exception": false,
     "start_time": "2022-11-17T17:37:30.122247",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# ODIN Kaggle - Train on SVHN and Test on CIFAR-10\n",
    "\n",
    "This notebook is set up to run on Kaggle since they have free GPU hours. At a high level, this notebook\n",
    "- Clones my (Harry's) forked repo of ODIN since their code has some bugs in Python 3 (I'm assuming their syntax was valid in Python 2 or something)\n",
    "- Downloads our model trained on SVHN\n",
    "- Downloads CIFAR-10 dataset\n",
    "- Evaluates the model using ODIN and using the baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70f10867",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-17T17:37:30.136681Z",
     "iopub.status.busy": "2022-11-17T17:37:30.136176Z",
     "iopub.status.idle": "2022-11-17T17:37:34.051255Z",
     "shell.execute_reply": "2022-11-17T17:37:34.049930Z"
    },
    "papermill": {
     "duration": 3.923427,
     "end_time": "2022-11-17T17:37:34.053989",
     "exception": false,
     "start_time": "2022-11-17T17:37:30.130562",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'BDL-OOD'...\r\n",
      "remote: Enumerating objects: 177, done.\u001b[K\r\n",
      "remote: Counting objects: 100% (177/177), done.\u001b[K\r\n",
      "remote: Compressing objects: 100% (129/129), done.\u001b[K\r\n",
      "remote: Total 177 (delta 57), reused 154 (delta 38), pack-reused 0\u001b[K\r\n",
      "Receiving objects: 100% (177/177), 32.38 MiB | 27.38 MiB/s, done.\r\n",
      "Resolving deltas: 100% (57/57), done.\r\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/jiajinghu19/BDL-OOD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ce79f8e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-17T17:37:34.062218Z",
     "iopub.status.busy": "2022-11-17T17:37:34.061837Z",
     "iopub.status.idle": "2022-11-17T17:37:35.981226Z",
     "shell.execute_reply": "2022-11-17T17:37:35.979919Z"
    },
    "papermill": {
     "duration": 1.926345,
     "end_time": "2022-11-17T17:37:35.983866",
     "exception": false,
     "start_time": "2022-11-17T17:37:34.057521",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working/BDL-OOD/src/ODIN/odin_fork/models\n",
      "Densenet_Train_SVHN_4.3_Percent_Error.pth\r\n"
     ]
    }
   ],
   "source": [
    "# move the pre-SVHN-trained model here\n",
    "%cd /kaggle/working/BDL-OOD/src/ODIN/odin_fork/models\n",
    "!mv ../../Densenet_Train_SVHN_Kaggle/Densenet_Train_SVHN_4.3_Percent_Error.pth ./\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7db0f359",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-17T17:37:35.991875Z",
     "iopub.status.busy": "2022-11-17T17:37:35.991557Z",
     "iopub.status.idle": "2022-11-17T17:37:37.884192Z",
     "shell.execute_reply": "2022-11-17T17:37:37.882894Z"
    },
    "papermill": {
     "duration": 1.899714,
     "end_time": "2022-11-17T17:37:37.886902",
     "exception": false,
     "start_time": "2022-11-17T17:37:35.987188",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working/BDL-OOD/src/ODIN/odin_fork/code\n"
     ]
    }
   ],
   "source": [
    "%cd /kaggle/working/BDL-OOD/src/ODIN/odin_fork/code\n",
    "!rm densenet.py # delete the densenet.py file\n",
    "!mv ../../Densenet_Train_SVHN_Kaggle/densenet.py ./ # move the correct densenet.py file here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8116795b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-17T17:37:37.896304Z",
     "iopub.status.busy": "2022-11-17T17:37:37.895468Z",
     "iopub.status.idle": "2022-11-17T17:37:37.912560Z",
     "shell.execute_reply": "2022-11-17T17:37:37.911046Z"
    },
    "papermill": {
     "duration": 0.024757,
     "end_time": "2022-11-17T17:37:37.915271",
     "exception": false,
     "start_time": "2022-11-17T17:37:37.890514",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting calData.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile calData.py\n",
    "# %load calData.py\n",
    "# Copyright (c) 2017-present, Facebook, Inc.\n",
    "# All rights reserved.\n",
    "#\n",
    "# This source code is licensed under the license found in the\n",
    "# LICENSE file in the root directory of this source tree.\n",
    "#\n",
    "\n",
    "\"\"\"\n",
    "Created on Sat Sep 19 20:55:56 2015\n",
    "\n",
    "@author: liangshiyu\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import print_function\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import time\n",
    "from scipy import misc\n",
    "\n",
    "def reshape_output(output):\n",
    "    return torch.reshape(output, (1, 10))\n",
    "\n",
    "def testData(net1, criterion, CUDA_DEVICE, testloader_in, testloader_out, nnName, in_data_name, out_data_name, noiseMagnitude1, temper):\n",
    "    t0 = time.time()\n",
    "    f1 = open(\"./softmax_scores/confidence_Base_In.txt\", 'w')\n",
    "    f2 = open(\"./softmax_scores/confidence_Base_Out.txt\", 'w')\n",
    "    g1 = open(\"./softmax_scores/confidence_Our_In.txt\", 'w')\n",
    "    g2 = open(\"./softmax_scores/confidence_Our_Out.txt\", 'w')\n",
    "    N = 10000\n",
    "    if out_data_name == \"iSUN\":\n",
    "        N = 8925\n",
    "        print(\"Processing in-distribution images\")\n",
    "########################################In-distribution###########################################\n",
    "    for j, data in enumerate(testloader_in):\n",
    "        if j<1000: continue\n",
    "        images, _ = data\n",
    "        \n",
    "        inputs = Variable(images.cuda(CUDA_DEVICE), requires_grad = True)\n",
    "        outputs = reshape_output(net1(inputs))\n",
    "        \n",
    "\n",
    "        # Calculating the confidence of the output, no perturbation added here, no temperature scaling used\n",
    "        nnOutputs = outputs.data.cpu()\n",
    "        nnOutputs = nnOutputs.numpy()\n",
    "        nnOutputs = nnOutputs[0]\n",
    "        nnOutputs = nnOutputs - np.max(nnOutputs)\n",
    "        nnOutputs = np.exp(nnOutputs)/np.sum(np.exp(nnOutputs))\n",
    "        f1.write(\"{}, {}, {}\\n\".format(temper, noiseMagnitude1, np.max(nnOutputs)))\n",
    "        \n",
    "        # Using temperature scaling\n",
    "        outputs = outputs / temper\n",
    "\t\n",
    "        # Calculating the perturbation we need to add, that is,\n",
    "        # the sign of gradient of cross entropy loss w.r.t. input\n",
    "        maxIndexTemp = np.argmax(nnOutputs)\n",
    "        labels = Variable(torch.LongTensor([maxIndexTemp]).cuda(CUDA_DEVICE))\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        \n",
    "        # Normalizing the gradient to binary in {0, 1}\n",
    "        gradient =  torch.ge(inputs.grad.data, 0)\n",
    "        gradient = (gradient.float() - 0.5) * 2\n",
    "        # Normalizing the gradient to the same space of image\n",
    "        gradient[0][0] = (gradient[0][0] )/(63.0/255.0)\n",
    "        gradient[0][1] = (gradient[0][1] )/(62.1/255.0)\n",
    "        gradient[0][2] = (gradient[0][2])/(66.7/255.0)\n",
    "        # Adding small perturbations to images\n",
    "        tempInputs = torch.add(inputs.data,  -noiseMagnitude1, gradient)\n",
    "        outputs = reshape_output(net1(Variable(tempInputs)))\n",
    "        outputs = outputs / temper\n",
    "        # Calculating the confidence after adding perturbations\n",
    "        nnOutputs = outputs.data.cpu()\n",
    "        nnOutputs = nnOutputs.numpy()\n",
    "        nnOutputs = nnOutputs[0]\n",
    "        nnOutputs = nnOutputs - np.max(nnOutputs)\n",
    "        nnOutputs = np.exp(nnOutputs)/np.sum(np.exp(nnOutputs))\n",
    "        g1.write(\"{}, {}, {}\\n\".format(temper, noiseMagnitude1, np.max(nnOutputs)))\n",
    "        if j % 100 == 99:\n",
    "            print(\"{:4}/{:4} images processed, {:.1f} seconds used.\".format(j+1-1000, N-1000, time.time()-t0))\n",
    "            t0 = time.time()\n",
    "        \n",
    "        if j == N - 1: break\n",
    "\n",
    "\n",
    "    t0 = time.time()\n",
    "    print(\"Processing out-of-distribution images\")\n",
    "###################################Out-of-Distributions#####################################\n",
    "    for j, data in enumerate(testloader_out):\n",
    "        if j<1000: continue\n",
    "        images, _ = data\n",
    "    \n",
    "    \n",
    "        inputs = Variable(images.cuda(CUDA_DEVICE), requires_grad = True)\n",
    "        outputs = reshape_output(net1(inputs))\n",
    "        \n",
    "\n",
    "\n",
    "        # Calculating the confidence of the output, no perturbation added here\n",
    "        nnOutputs = outputs.data.cpu()\n",
    "        nnOutputs = nnOutputs.numpy()\n",
    "        nnOutputs = nnOutputs[0]\n",
    "        nnOutputs = nnOutputs - np.max(nnOutputs)\n",
    "        nnOutputs = np.exp(nnOutputs)/np.sum(np.exp(nnOutputs))\n",
    "        f2.write(\"{}, {}, {}\\n\".format(temper, noiseMagnitude1, np.max(nnOutputs)))\n",
    "        \n",
    "        # Using temperature scaling\n",
    "        outputs = outputs / temper\n",
    "  \n",
    "  \n",
    "        # Calculating the perturbation we need to add, that is,\n",
    "        # the sign of gradient of cross entropy loss w.r.t. input\n",
    "        maxIndexTemp = np.argmax(nnOutputs)\n",
    "        labels = Variable(torch.LongTensor([maxIndexTemp]).cuda(CUDA_DEVICE))\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        \n",
    "        # Normalizing the gradient to binary in {0, 1}\n",
    "        gradient =  (torch.ge(inputs.grad.data, 0))\n",
    "        gradient = (gradient.float() - 0.5) * 2\n",
    "        # Normalizing the gradient to the same space of image\n",
    "        gradient[0][0] = (gradient[0][0] )/(63.0/255.0)\n",
    "        gradient[0][1] = (gradient[0][1] )/(62.1/255.0)\n",
    "        gradient[0][2] = (gradient[0][2])/(66.7/255.0)\n",
    "        # Adding small perturbations to images\n",
    "        tempInputs = torch.add(inputs.data,  -noiseMagnitude1, gradient)\n",
    "        outputs = reshape_output(net1(Variable(tempInputs)))\n",
    "        outputs = outputs / temper\n",
    "        # Calculating the confidence after adding perturbations\n",
    "        nnOutputs = outputs.data.cpu()\n",
    "        nnOutputs = nnOutputs.numpy()\n",
    "        nnOutputs = nnOutputs[0]\n",
    "        nnOutputs = nnOutputs - np.max(nnOutputs)\n",
    "        nnOutputs = np.exp(nnOutputs)/np.sum(np.exp(nnOutputs))\n",
    "        g2.write(\"{}, {}, {}\\n\".format(temper, noiseMagnitude1, np.max(nnOutputs)))\n",
    "        if j % 100 == 99:\n",
    "            print(\"{:4}/{:4} images processed, {:.1f} seconds used.\".format(j+1-1000, N-1000, time.time()-t0))\n",
    "            t0 = time.time()\n",
    "\n",
    "        if j== N-1: break\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def testGaussian(net1, criterion, CUDA_DEVICE, testloader_in, testloader_out, nnName, out_data_name, noiseMagnitude1, temper):\n",
    "    t0 = time.time()\n",
    "    f1 = open(\"./softmax_scores/confidence_Base_In.txt\", 'w')\n",
    "    f2 = open(\"./softmax_scores/confidence_Base_Out.txt\", 'w')\n",
    "    g1 = open(\"./softmax_scores/confidence_Our_In.txt\", 'w')\n",
    "    g2 = open(\"./softmax_scores/confidence_Our_Out.txt\", 'w')\n",
    "########################################In-Distribution###############################################\n",
    "    N = 10000\n",
    "    print(\"Processing in-distribution images\")\n",
    "    for j, data in enumerate(testloader_in):\n",
    "        \n",
    "        if j<1000: continue\n",
    "        images, _ = data\n",
    "        \n",
    "        inputs = Variable(images.cuda(CUDA_DEVICE), requires_grad = True)\n",
    "        outputs = net1(inputs)\n",
    "        \n",
    "        \n",
    "        # Calculating the confidence of the output, no perturbation added here\n",
    "        nnOutputs = outputs.data.cpu()\n",
    "        nnOutputs = nnOutputs.numpy()\n",
    "        nnOutputs = nnOutputs[0]\n",
    "        nnOutputs = nnOutputs - np.max(nnOutputs)\n",
    "        nnOutputs = np.exp(nnOutputs)/np.sum(np.exp(nnOutputs))\n",
    "        f1.write(\"{}, {}, {}\\n\".format(temper, noiseMagnitude1, np.max(nnOutputs)))\n",
    "        \n",
    "        # Using temperature scaling\n",
    "        outputs = outputs / temper\n",
    "        \n",
    "        # Calculating the perturbation we need to add, that is,\n",
    "        # the sign of gradient of cross entropy loss w.r.t. input\n",
    "        maxIndexTemp = np.argmax(nnOutputs)\n",
    "        labels = Variable(torch.LongTensor([maxIndexTemp]).cuda(CUDA_DEVICE))\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        \n",
    "        \n",
    "        # Normalizing the gradient to binary in {0, 1}\n",
    "        gradient =  (torch.ge(inputs.grad.data, 0))\n",
    "        gradient = (gradient.float() - 0.5) * 2\n",
    "        # Normalizing the gradient to the same space of image\n",
    "        gradient[0][0] = (gradient[0][0] )/(63.0/255.0)\n",
    "        gradient[0][1] = (gradient[0][1] )/(62.1/255.0)\n",
    "        gradient[0][2] = (gradient[0][2])/(66.7/255.0)\n",
    "        # Adding small perturbations to images\n",
    "        tempInputs = torch.add(inputs.data,  -noiseMagnitude1, gradient)\n",
    "        outputs = net1(Variable(tempInputs))\n",
    "        outputs = outputs / temper\n",
    "        # Calculating the confidence after adding perturbations\n",
    "        nnOutputs = outputs.data.cpu()\n",
    "        nnOutputs = nnOutputs.numpy()\n",
    "        nnOutputs = nnOutputs[0]\n",
    "        nnOutputs = nnOutputs - np.max(nnOutputs)\n",
    "        nnOutputs = np.exp(nnOutputs)/np.sum(np.exp(nnOutputs))\n",
    "\n",
    "        g1.write(\"{}, {}, {}\\n\".format(temper, noiseMagnitude1, np.max(nnOutputs)))\n",
    "        if j % 100 == 99:\n",
    "            print(\"{:4}/{:4} images processed, {:.1f} seconds used.\".format(j+1-1000, N-1000, time.time()-t0))\n",
    "            t0 = time.time()\n",
    "\n",
    "    \n",
    "    \n",
    "########################################Out-of-Distribution######################################\n",
    "    print(\"Processing out-of-distribution images\")\n",
    "    for j, data in enumerate(testloader_out):\n",
    "        if j<1000: continue\n",
    "        \n",
    "        images = torch.randn(1,3,32,32) + 0.5\n",
    "        images = torch.clamp(images, 0, 1)\n",
    "        images[0][0] = (images[0][0] - 125.3/255) / (63.0/255)\n",
    "        images[0][1] = (images[0][1] - 123.0/255) / (62.1/255)\n",
    "        images[0][2] = (images[0][2] - 113.9/255) / (66.7/255)\n",
    "        \n",
    "        \n",
    "        inputs = Variable(images.cuda(CUDA_DEVICE), requires_grad = True)\n",
    "        outputs = net1(inputs)\n",
    "        \n",
    "        \n",
    "        \n",
    "        # Calculating the confidence of the output, no perturbation added here\n",
    "        nnOutputs = outputs.data.cpu()\n",
    "        nnOutputs = nnOutputs.numpy()\n",
    "        nnOutputs = nnOutputs[0]\n",
    "        nnOutputs = nnOutputs - np.max(nnOutputs)\n",
    "        nnOutputs = np.exp(nnOutputs)/np.sum(np.exp(nnOutputs))\n",
    "        f2.write(\"{}, {}, {}\\n\".format(temper, noiseMagnitude1, np.max(nnOutputs)))\n",
    "        \n",
    "        # Using temperature scaling\n",
    "        outputs = outputs / temper\n",
    "        \n",
    "        # Calculating the perturbation we need to add, that is,\n",
    "        # the sign of gradient of cross entropy loss w.r.t. input\n",
    "        maxIndexTemp = np.argmax(nnOutputs)\n",
    "        labels = Variable(torch.LongTensor([maxIndexTemp]).cuda(CUDA_DEVICE))\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        \n",
    "        # Normalizing the gradient to binary in {0, 1}\n",
    "        gradient =  (torch.ge(inputs.grad.data, 0))\n",
    "        gradient = (gradient.float() - 0.5) * 2\n",
    "        # Normalizing the gradient to the same space of image\n",
    "        gradient[0][0] = (gradient[0][0] )/(63.0/255.0)\n",
    "        gradient[0][1] = (gradient[0][1] )/(62.1/255.0)\n",
    "        gradient[0][2] = (gradient[0][2])/(66.7/255.0)\n",
    "        # Adding small perturbations to images\n",
    "        tempInputs = torch.add(inputs.data,  -noiseMagnitude1, gradient)\n",
    "        outputs = net1(Variable(tempInputs))\n",
    "        outputs = outputs / temper\n",
    "        # Calculating the confidence after adding perturbations\n",
    "        nnOutputs = outputs.data.cpu()\n",
    "        nnOutputs = nnOutputs.numpy()\n",
    "        nnOutputs = nnOutputs[0]\n",
    "        nnOutputs = nnOutputs - np.max(nnOutputs)\n",
    "        nnOutputs = np.exp(nnOutputs)/np.sum(np.exp(nnOutputs))\n",
    "        g2.write(\"{}, {}, {}\\n\".format(temper, noiseMagnitude1, np.max(nnOutputs)))\n",
    "        \n",
    "        if j % 100 == 99:\n",
    "            print(\"{:4}/{:4} images processed, {:.1f} seconds used.\".format(j+1-1000, N-1000, time.time()-t0))\n",
    "            t0 = time.time()\n",
    "\n",
    "        if j== N-1: break\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def testUni(net1, criterion, CUDA_DEVICE, testloader_in, testloader_out, nnName, out_data_name, noiseMagnitude1, temper):\n",
    "    t0 = time.time()\n",
    "    f1 = open(\"./softmax_scores/confidence_Base_In.txt\", 'w')\n",
    "    f2 = open(\"./softmax_scores/confidence_Base_Out.txt\", 'w')\n",
    "    g1 = open(\"./softmax_scores/confidence_Our_In.txt\", 'w')\n",
    "    g2 = open(\"./softmax_scores/confidence_Our_Out.txt\", 'w')\n",
    "########################################In-Distribution###############################################\n",
    "    N = 10000\n",
    "    print(\"Processing in-distribution images\")\n",
    "    for j, data in enumerate(testloader_in):\n",
    "        if j<1000: continue\n",
    "        \n",
    "        images, _ = data\n",
    "        \n",
    "        inputs = Variable(images.cuda(CUDA_DEVICE), requires_grad = True)\n",
    "        outputs = net1(inputs)\n",
    "        \n",
    "        \n",
    "        # Calculating the confidence of the output, no perturbation added here\n",
    "        nnOutputs = outputs.data.cpu()\n",
    "        nnOutputs = nnOutputs.numpy()\n",
    "        nnOutputs = nnOutputs[0]\n",
    "        nnOutputs = nnOutputs - np.max(nnOutputs)\n",
    "        nnOutputs = np.exp(nnOutputs)/np.sum(np.exp(nnOutputs))\n",
    "        f1.write(\"{}, {}, {}\\n\".format(temper, noiseMagnitude1, np.max(nnOutputs)))\n",
    "        \n",
    "        # Using temperature scaling\n",
    "        outputs = outputs / temper\n",
    "        \n",
    "        # Calculating the perturbation we need to add, that is,\n",
    "        # the sign of gradient of cross entropy loss w.r.t. input\n",
    "        maxIndexTemp = np.argmax(nnOutputs)\n",
    "        labels = Variable(torch.LongTensor([maxIndexTemp]).cuda(CUDA_DEVICE))\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        \n",
    "        \n",
    "        # Normalizing the gradient to binary in {0, 1}\n",
    "        gradient =  (torch.ge(inputs.grad.data, 0))\n",
    "        gradient = (gradient.float() - 0.5) * 2\n",
    "        # Normalizing the gradient to the same space of image\n",
    "        gradient[0][0] = (gradient[0][0] )/(63.0/255.0)\n",
    "        gradient[0][1] = (gradient[0][1] )/(62.1/255.0)\n",
    "        gradient[0][2] = (gradient[0][2])/(66.7/255.0)\n",
    "        # Adding small perturbations to images\n",
    "        tempInputs = torch.add(inputs.data,  -noiseMagnitude1, gradient)\n",
    "        outputs = net1(Variable(tempInputs))\n",
    "        outputs = outputs / temper\n",
    "        # Calculating the confidence after adding perturbations\n",
    "        nnOutputs = outputs.data.cpu()\n",
    "        nnOutputs = nnOutputs.numpy()\n",
    "        nnOutputs = nnOutputs[0]\n",
    "        nnOutputs = nnOutputs - np.max(nnOutputs)\n",
    "        nnOutputs = np.exp(nnOutputs)/np.sum(np.exp(nnOutputs))\n",
    "\n",
    "        g1.write(\"{}, {}, {}\\n\".format(temper, noiseMagnitude1, np.max(nnOutputs)))\n",
    "        if j % 100 == 99:\n",
    "            print(\"{:4}/{:4}  images processed, {:.1f} seconds used.\".format(j+1-1000, N-1000, time.time()-t0))\n",
    "            t0 = time.time()\n",
    "\n",
    "\n",
    "\n",
    "########################################Out-of-Distribution######################################\n",
    "    print(\"Processing out-of-distribution images\")\n",
    "    for j, data in enumerate(testloader_out):\n",
    "        if j<1000: continue\n",
    "        \n",
    "        images = torch.rand(1,3,32,32)\n",
    "        images[0][0] = (images[0][0] - 125.3/255) / (63.0/255)\n",
    "        images[0][1] = (images[0][1] - 123.0/255) / (62.1/255)\n",
    "        images[0][2] = (images[0][2] - 113.9/255) / (66.7/255)\n",
    "        \n",
    "        \n",
    "        inputs = Variable(images.cuda(CUDA_DEVICE), requires_grad = True)\n",
    "        outputs = net1(inputs)\n",
    "        \n",
    "        \n",
    "        \n",
    "        # Calculating the confidence of the output, no perturbation added here\n",
    "        nnOutputs = outputs.data.cpu()\n",
    "        nnOutputs = nnOutputs.numpy()\n",
    "        nnOutputs = nnOutputs[0]\n",
    "        nnOutputs = nnOutputs - np.max(nnOutputs)\n",
    "        nnOutputs = np.exp(nnOutputs)/np.sum(np.exp(nnOutputs))\n",
    "        f2.write(\"{}, {}, {}\\n\".format(temper, noiseMagnitude1, np.max(nnOutputs)))\n",
    "        \n",
    "        # Using temperature scaling\n",
    "        outputs = outputs / temper\n",
    "        \n",
    "        # Calculating the perturbation we need to add, that is,\n",
    "        # the sign of gradient of cross entropy loss w.r.t. input\n",
    "        maxIndexTemp = np.argmax(nnOutputs)\n",
    "        labels = Variable(torch.LongTensor([maxIndexTemp]).cuda(CUDA_DEVICE))\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        \n",
    "        # Normalizing the gradient to binary in {0, 1}\n",
    "        gradient =  (torch.ge(inputs.grad.data, 0))\n",
    "        gradient = (gradient.float() - 0.5) * 2\n",
    "        # Normalizing the gradient to the same space of image\n",
    "        gradient[0][0] = (gradient[0][0] )/(63.0/255.0)\n",
    "        gradient[0][1] = (gradient[0][1] )/(62.1/255.0)\n",
    "        gradient[0][2] = (gradient[0][2])/(66.7/255.0)\n",
    "        # Adding small perturbations to images\n",
    "        tempInputs = torch.add(inputs.data,  -noiseMagnitude1, gradient)\n",
    "        outputs = net1(Variable(tempInputs))\n",
    "        outputs = outputs / temper\n",
    "        # Calculating the confidence after adding perturbations\n",
    "        nnOutputs = outputs.data.cpu()\n",
    "        nnOutputs = nnOutputs.numpy()\n",
    "        nnOutputs = nnOutputs[0]\n",
    "        nnOutputs = nnOutputs - np.max(nnOutputs)\n",
    "        nnOutputs = np.exp(nnOutputs)/np.sum(np.exp(nnOutputs))\n",
    "        g2.write(\"{}, {}, {}\\n\".format(temper, noiseMagnitude1, np.max(nnOutputs)))\n",
    "        if j % 100 == 99:\n",
    "            print(\"{:4}/{:4} images processed, {:.1f} seconds used.\".format(j+1-1000, N-1000, time.time()-t0))\n",
    "            t0 = time.time()\n",
    "\n",
    "        if j== N-1: break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bf0c674c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-17T17:37:37.923491Z",
     "iopub.status.busy": "2022-11-17T17:37:37.923217Z",
     "iopub.status.idle": "2022-11-17T17:54:07.513359Z",
     "shell.execute_reply": "2022-11-17T17:54:07.512194Z"
    },
    "papermill": {
     "duration": 989.596984,
     "end_time": "2022-11-17T17:54:07.515866",
     "exception": false,
     "start_time": "2022-11-17T17:37:37.918882",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ../data/cifar-10-python.tar.gz\r\n",
      "170499072it [00:03, 43188340.66it/s]                                            \r\n",
      "Extracting ../data/cifar-10-python.tar.gz to ../data\r\n",
      "Downloading http://ufldl.stanford.edu/housenumbers/test_32x32.mat to svhn/test_32x32.mat\r\n",
      "64275456it [00:00, 65006877.61it/s]                                             \r\n",
      "/kaggle/working/BDL-OOD/src/ODIN/odin_fork/code/densenet.py:115: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\r\n",
      "  out = F.log_softmax(self.fc(out))\r\n",
      "/kaggle/working/BDL-OOD/src/ODIN/odin_fork/code/calData.py:76: UserWarning: This overload of add is deprecated:\r\n",
      "\tadd(Tensor input, Number alpha, Tensor other, *, Tensor out)\r\n",
      "Consider using one of the following signatures instead:\r\n",
      "\tadd(Tensor input, Tensor other, *, Number alpha, Tensor out) (Triggered internally at  /usr/local/src/pytorch/torch/csrc/utils/python_arg_parser.cpp:1055.)\r\n",
      "  tempInputs = torch.add(inputs.data,  -noiseMagnitude1, gradient)\r\n",
      " 100/9000 images processed, 14.1 seconds used.\r\n",
      " 200/9000 images processed, 4.8 seconds used.\r\n",
      " 300/9000 images processed, 5.0 seconds used.\r\n",
      " 400/9000 images processed, 5.3 seconds used.\r\n",
      " 500/9000 images processed, 5.1 seconds used.\r\n",
      " 600/9000 images processed, 4.8 seconds used.\r\n",
      " 700/9000 images processed, 4.9 seconds used.\r\n",
      " 800/9000 images processed, 4.9 seconds used.\r\n",
      " 900/9000 images processed, 4.7 seconds used.\r\n",
      "1000/9000 images processed, 5.4 seconds used.\r\n",
      "1100/9000 images processed, 4.8 seconds used.\r\n",
      "1200/9000 images processed, 5.1 seconds used.\r\n",
      "1300/9000 images processed, 4.8 seconds used.\r\n",
      "1400/9000 images processed, 5.0 seconds used.\r\n",
      "1500/9000 images processed, 4.7 seconds used.\r\n",
      "1600/9000 images processed, 5.3 seconds used.\r\n",
      "1700/9000 images processed, 5.2 seconds used.\r\n",
      "1800/9000 images processed, 4.8 seconds used.\r\n",
      "1900/9000 images processed, 4.9 seconds used.\r\n",
      "2000/9000 images processed, 4.7 seconds used.\r\n",
      "2100/9000 images processed, 5.2 seconds used.\r\n",
      "2200/9000 images processed, 4.8 seconds used.\r\n",
      "2300/9000 images processed, 5.3 seconds used.\r\n",
      "2400/9000 images processed, 4.8 seconds used.\r\n",
      "2500/9000 images processed, 5.0 seconds used.\r\n",
      "2600/9000 images processed, 4.7 seconds used.\r\n",
      "2700/9000 images processed, 4.8 seconds used.\r\n",
      "2800/9000 images processed, 5.0 seconds used.\r\n",
      "2900/9000 images processed, 5.2 seconds used.\r\n",
      "3000/9000 images processed, 5.0 seconds used.\r\n",
      "3100/9000 images processed, 4.7 seconds used.\r\n",
      "3200/9000 images processed, 5.0 seconds used.\r\n",
      "3300/9000 images processed, 4.7 seconds used.\r\n",
      "3400/9000 images processed, 5.0 seconds used.\r\n",
      "3500/9000 images processed, 5.2 seconds used.\r\n",
      "3600/9000 images processed, 4.8 seconds used.\r\n",
      "3700/9000 images processed, 5.0 seconds used.\r\n",
      "3800/9000 images processed, 4.7 seconds used.\r\n",
      "3900/9000 images processed, 5.0 seconds used.\r\n",
      "4000/9000 images processed, 4.8 seconds used.\r\n",
      "4100/9000 images processed, 5.0 seconds used.\r\n",
      "4200/9000 images processed, 5.2 seconds used.\r\n",
      "4300/9000 images processed, 5.0 seconds used.\r\n",
      "4400/9000 images processed, 4.8 seconds used.\r\n",
      "4500/9000 images processed, 4.8 seconds used.\r\n",
      "4600/9000 images processed, 5.1 seconds used.\r\n",
      "4700/9000 images processed, 4.7 seconds used.\r\n",
      "4800/9000 images processed, 5.4 seconds used.\r\n",
      "4900/9000 images processed, 4.7 seconds used.\r\n",
      "5000/9000 images processed, 4.9 seconds used.\r\n",
      "5100/9000 images processed, 4.7 seconds used.\r\n",
      "5200/9000 images processed, 5.0 seconds used.\r\n",
      "5300/9000 images processed, 4.7 seconds used.\r\n",
      "5400/9000 images processed, 5.2 seconds used.\r\n",
      "5500/9000 images processed, 5.2 seconds used.\r\n",
      "5600/9000 images processed, 4.8 seconds used.\r\n",
      "5700/9000 images processed, 4.9 seconds used.\r\n",
      "5800/9000 images processed, 4.8 seconds used.\r\n",
      "5900/9000 images processed, 5.0 seconds used.\r\n",
      "6000/9000 images processed, 4.9 seconds used.\r\n",
      "6100/9000 images processed, 5.5 seconds used.\r\n",
      "6200/9000 images processed, 4.8 seconds used.\r\n",
      "6300/9000 images processed, 5.0 seconds used.\r\n",
      "6400/9000 images processed, 4.8 seconds used.\r\n",
      "6500/9000 images processed, 4.7 seconds used.\r\n",
      "6600/9000 images processed, 4.9 seconds used.\r\n",
      "6700/9000 images processed, 5.2 seconds used.\r\n",
      "6800/9000 images processed, 5.0 seconds used.\r\n",
      "6900/9000 images processed, 4.7 seconds used.\r\n",
      "7000/9000 images processed, 4.9 seconds used.\r\n",
      "7100/9000 images processed, 4.8 seconds used.\r\n",
      "7200/9000 images processed, 5.1 seconds used.\r\n",
      "7300/9000 images processed, 5.1 seconds used.\r\n",
      "7400/9000 images processed, 5.0 seconds used.\r\n",
      "7500/9000 images processed, 4.8 seconds used.\r\n",
      "7600/9000 images processed, 4.8 seconds used.\r\n",
      "7700/9000 images processed, 5.1 seconds used.\r\n",
      "7800/9000 images processed, 4.8 seconds used.\r\n",
      "7900/9000 images processed, 5.0 seconds used.\r\n",
      "8000/9000 images processed, 5.4 seconds used.\r\n",
      "8100/9000 images processed, 4.6 seconds used.\r\n",
      "8200/9000 images processed, 4.7 seconds used.\r\n",
      "8300/9000 images processed, 4.7 seconds used.\r\n",
      "8400/9000 images processed, 4.8 seconds used.\r\n",
      "8500/9000 images processed, 4.8 seconds used.\r\n",
      "8600/9000 images processed, 5.3 seconds used.\r\n",
      "8700/9000 images processed, 4.7 seconds used.\r\n",
      "8800/9000 images processed, 4.7 seconds used.\r\n",
      "8900/9000 images processed, 4.7 seconds used.\r\n",
      "9000/9000 images processed, 4.7 seconds used.\r\n",
      "Processing out-of-distribution images\r\n",
      " 100/9000 images processed, 7.1 seconds used.\r\n",
      " 200/9000 images processed, 5.7 seconds used.\r\n",
      " 300/9000 images processed, 4.7 seconds used.\r\n",
      " 400/9000 images processed, 4.7 seconds used.\r\n",
      " 500/9000 images processed, 4.9 seconds used.\r\n",
      " 600/9000 images processed, 4.7 seconds used.\r\n",
      " 700/9000 images processed, 5.0 seconds used.\r\n",
      " 800/9000 images processed, 4.8 seconds used.\r\n",
      " 900/9000 images processed, 5.6 seconds used.\r\n",
      "1000/9000 images processed, 4.7 seconds used.\r\n",
      "1100/9000 images processed, 5.0 seconds used.\r\n",
      "1200/9000 images processed, 4.8 seconds used.\r\n",
      "1300/9000 images processed, 5.3 seconds used.\r\n",
      "1400/9000 images processed, 5.0 seconds used.\r\n",
      "1500/9000 images processed, 5.1 seconds used.\r\n",
      "1600/9000 images processed, 4.9 seconds used.\r\n",
      "1700/9000 images processed, 4.8 seconds used.\r\n",
      "1800/9000 images processed, 5.0 seconds used.\r\n",
      "1900/9000 images processed, 4.7 seconds used.\r\n",
      "2000/9000 images processed, 5.1 seconds used.\r\n",
      "2100/9000 images processed, 5.1 seconds used.\r\n",
      "2200/9000 images processed, 4.9 seconds used.\r\n",
      "2300/9000 images processed, 4.8 seconds used.\r\n",
      "2400/9000 images processed, 4.8 seconds used.\r\n",
      "2500/9000 images processed, 4.9 seconds used.\r\n",
      "2600/9000 images processed, 4.8 seconds used.\r\n",
      "2700/9000 images processed, 5.0 seconds used.\r\n",
      "2800/9000 images processed, 5.1 seconds used.\r\n",
      "2900/9000 images processed, 4.9 seconds used.\r\n",
      "3000/9000 images processed, 4.7 seconds used.\r\n",
      "3100/9000 images processed, 4.8 seconds used.\r\n",
      "3200/9000 images processed, 4.9 seconds used.\r\n",
      "3300/9000 images processed, 4.8 seconds used.\r\n",
      "3400/9000 images processed, 5.5 seconds used.\r\n",
      "3500/9000 images processed, 4.8 seconds used.\r\n",
      "3600/9000 images processed, 5.0 seconds used.\r\n",
      "3700/9000 images processed, 4.7 seconds used.\r\n",
      "3800/9000 images processed, 4.9 seconds used.\r\n",
      "3900/9000 images processed, 4.8 seconds used.\r\n",
      "4000/9000 images processed, 5.4 seconds used.\r\n",
      "4100/9000 images processed, 4.7 seconds used.\r\n",
      "4200/9000 images processed, 4.6 seconds used.\r\n",
      "4300/9000 images processed, 5.0 seconds used.\r\n",
      "4400/9000 images processed, 4.7 seconds used.\r\n",
      "4500/9000 images processed, 5.0 seconds used.\r\n",
      "4600/9000 images processed, 4.8 seconds used.\r\n",
      "4700/9000 images processed, 5.3 seconds used.\r\n",
      "4800/9000 images processed, 4.6 seconds used.\r\n",
      "4900/9000 images processed, 4.9 seconds used.\r\n",
      "5000/9000 images processed, 4.7 seconds used.\r\n",
      "5100/9000 images processed, 4.8 seconds used.\r\n",
      "5200/9000 images processed, 5.0 seconds used.\r\n",
      "5300/9000 images processed, 5.2 seconds used.\r\n",
      "5400/9000 images processed, 4.9 seconds used.\r\n",
      "5500/9000 images processed, 4.7 seconds used.\r\n",
      "5600/9000 images processed, 4.9 seconds used.\r\n",
      "5700/9000 images processed, 4.8 seconds used.\r\n",
      "5800/9000 images processed, 4.9 seconds used.\r\n",
      "5900/9000 images processed, 4.7 seconds used.\r\n",
      "6000/9000 images processed, 5.2 seconds used.\r\n",
      "6100/9000 images processed, 5.2 seconds used.\r\n",
      "6200/9000 images processed, 4.7 seconds used.\r\n",
      "6300/9000 images processed, 5.0 seconds used.\r\n",
      "6400/9000 images processed, 4.7 seconds used.\r\n",
      "6500/9000 images processed, 4.9 seconds used.\r\n",
      "6600/9000 images processed, 5.1 seconds used.\r\n",
      "6700/9000 images processed, 4.9 seconds used.\r\n",
      "6800/9000 images processed, 4.7 seconds used.\r\n",
      "6900/9000 images processed, 4.8 seconds used.\r\n",
      "7000/9000 images processed, 4.9 seconds used.\r\n",
      "7100/9000 images processed, 4.8 seconds used.\r\n",
      "7200/9000 images processed, 5.3 seconds used.\r\n",
      "7300/9000 images processed, 4.8 seconds used.\r\n",
      "7400/9000 images processed, 4.9 seconds used.\r\n",
      "7500/9000 images processed, 4.7 seconds used.\r\n",
      "7600/9000 images processed, 4.9 seconds used.\r\n",
      "7700/9000 images processed, 4.7 seconds used.\r\n",
      "7800/9000 images processed, 4.6 seconds used.\r\n",
      "7900/9000 images processed, 5.4 seconds used.\r\n",
      "8000/9000 images processed, 4.6 seconds used.\r\n",
      "8100/9000 images processed, 4.9 seconds used.\r\n",
      "8200/9000 images processed, 4.7 seconds used.\r\n",
      "8300/9000 images processed, 5.0 seconds used.\r\n",
      "8400/9000 images processed, 4.8 seconds used.\r\n",
      "8500/9000 images processed, 5.6 seconds used.\r\n",
      "8600/9000 images processed, 4.7 seconds used.\r\n",
      "8700/9000 images processed, 4.6 seconds used.\r\n",
      "8800/9000 images processed, 5.0 seconds used.\r\n",
      "8900/9000 images processed, 4.7 seconds used.\r\n",
      "9000/9000 images processed, 4.9 seconds used.\r\n",
      "Neural network architecture:                 Densenet\r\n",
      "In-distribution dataset:                         SVHN\r\n",
      "Out-of-distribution dataset:                 CIFAR-10\r\n",
      "\r\n",
      "                          Baseline         Our Method\r\n",
      "FPR at TPR 95%:              22.6%               9.8% \r\n",
      "Detection error:              9.0%               6.4%\r\n",
      "AUROC:                       96.6%              98.1%\r\n",
      "AUPR In:                     97.2%              98.4%\r\n",
      "AUPR Out:                    96.0%              97.9%\r\n"
     ]
    }
   ],
   "source": [
    "!python main.py --nn Densenet_Train_SVHN_4.3_Percent_Error --in_dataset SVHN --out_dataset CIFAR-10 --magnitude 0.0014 --temperature 1000 --gpu 0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1005.578939,
   "end_time": "2022-11-17T17:54:08.053382",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-11-17T17:37:22.474443",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
